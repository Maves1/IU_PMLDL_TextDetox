{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary-based Word Replacement\n",
    "\n",
    "This is a baseline approach. We simply check each word and remove toxic ones.\n",
    "\n",
    "We can also find a dataset that contains neutral alternatives to toxic words and\n",
    "use it to replace them instead of removing completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maves/Projects/Personal/InnopolisUniversity/Semester 7/IU_PMLDL_TextDetoxifier/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"../data/raw/filtered.tsv\"\n",
    "\n",
    "df = pd.read_csv(raw_path, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577772</th>\n",
       "      <td>577772</td>\n",
       "      <td>You didn't know that Estelle had stolen some f...</td>\n",
       "      <td>you didn't know that Estelle stole your fish f...</td>\n",
       "      <td>0.870322</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.949143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577773</th>\n",
       "      <td>577773</td>\n",
       "      <td>It'il suck the life out of you!</td>\n",
       "      <td>you'd be sucked out of your life!</td>\n",
       "      <td>0.722897</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.215794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577774</th>\n",
       "      <td>577774</td>\n",
       "      <td>I can't fuckin' take that, bruv.</td>\n",
       "      <td>I really can't take this.</td>\n",
       "      <td>0.617511</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.984538</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577775</th>\n",
       "      <td>577775</td>\n",
       "      <td>They called me a fucking hero. The truth is I ...</td>\n",
       "      <td>they said I was a hero, but I didn't care.</td>\n",
       "      <td>0.679613</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.991945</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577776</th>\n",
       "      <td>577776</td>\n",
       "      <td>I did not screw him.</td>\n",
       "      <td>I didn't fuck him.</td>\n",
       "      <td>0.868475</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>0.994174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>577777 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                          reference  \\\n",
       "0                0  If Alkar is flooding her with psychic waste, t...   \n",
       "1                1                          Now you're getting nasty.   \n",
       "2                2           Well, we could spare your life, for one.   \n",
       "3                3          Ah! Monkey, you've got to snap out of it.   \n",
       "4                4                   I've got orders to put her down.   \n",
       "...            ...                                                ...   \n",
       "577772      577772  You didn't know that Estelle had stolen some f...   \n",
       "577773      577773                    It'il suck the life out of you!   \n",
       "577774      577774                   I can't fuckin' take that, bruv.   \n",
       "577775      577775  They called me a fucking hero. The truth is I ...   \n",
       "577776      577776                               I did not screw him.   \n",
       "\n",
       "                                              translation  similarity  \\\n",
       "0       if Alkar floods her with her mental waste, it ...    0.785171   \n",
       "1                             you're becoming disgusting.    0.749687   \n",
       "2                           well, we can spare your life.    0.919051   \n",
       "3                            monkey, you have to wake up.    0.664333   \n",
       "4                              I have orders to kill her.    0.726639   \n",
       "...                                                   ...         ...   \n",
       "577772  you didn't know that Estelle stole your fish f...    0.870322   \n",
       "577773                  you'd be sucked out of your life!    0.722897   \n",
       "577774                          I really can't take this.    0.617511   \n",
       "577775         they said I was a hero, but I didn't care.    0.679613   \n",
       "577776                                 I didn't fuck him.    0.868475   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "0          0.010309  0.014195  0.981983  \n",
       "1          0.071429  0.065473  0.999039  \n",
       "2          0.268293  0.213313  0.985068  \n",
       "3          0.309524  0.053362  0.994215  \n",
       "4          0.181818  0.009402  0.999348  \n",
       "...             ...       ...       ...  \n",
       "577772     0.030769  0.000121  0.949143  \n",
       "577773     0.058824  0.996124  0.215794  \n",
       "577774     0.212121  0.984538  0.000049  \n",
       "577775     0.358209  0.991945  0.000124  \n",
       "577776     0.095238  0.009480  0.994174  \n",
       "\n",
       "[577777 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoverModel:\n",
    "    def __init__(self, toxic_words: set) -> None:\n",
    "        self.toxic_words = toxic_words\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    def detoxify(self, input: str):\n",
    "        tokenized = self.tokenizer.tokenize(input)\n",
    "\n",
    "        output_list = []\n",
    "        for token in tokenized:\n",
    "            if token not in self.toxic_words:\n",
    "                output_list.append(token)\n",
    "        \n",
    "        return \" \".join(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_toxic_words(path: str) -> set:\n",
    "    file = open(path)\n",
    "\n",
    "    toxic_words = set(file.read().strip().split(\"\\n\"))\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    return toxic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s_h_i_t', 'cox', 'dickhead', 'ballsack', 'damn', 'phuck', 'bitchin', 'buttplug', 'twat', 'shit', 'v1gra', 'fingerfucked ', 'fingerfucks ', 'fatass', 'a_s_s', 'cockhead', 'phuking', 'shemale', 'penis', 'fanyy', 'ballbag', 'tittiefucker', 'rectum', 'cocksuka', 'faggs', 'ejakulate', 'bitcher', 'sluts', 'sh!+', 'asses', 'butt', 'coksucka', 'viagra', 'mof0', 'mo-fo', 'goatse', 'hardcoresex ', 'donkeyribber', 'mothafucker', 'blowjob', 'pissed', 'shitfuck', 'shagging', 'bitchers', 'vulva', 'chink', 'motherfuckers', 'crap', 'bi+ch', 'motherfucker', 'snatch', 'goddamned', 'screwing', 'master-bate', 'hoer', 'fuckwit', 'heshe', 'fudge packer', 'muthafuckker', 'horny', 'skank', 'mothafucked ', 'whoar', 'knobead', 'vagina', 'cocksucker', 'clit', 'n1gger', 'god-damned', 'mutha', 'tosser', 'nazi', 'kunilingus', 'fuckheads', 'turd', 'fannyfucker', 'd1ck', 'goddamn', 'faggitt', 'tittywank', 'phuked', 'fannyflaps', 'masochist', 'blow job', 'shitters ', 'fags', 'knobjocky', 'testical', 'fistfucker ', 'willy', 'wang', 'kum', 'son-of-a-bitch', 'pissflaps', 'fucked', 'pussi', 'ma5terb8', 'fuckme ', 'fuckin', 'cock', 'phukked', 'jap', 'fukkin', 'anal', 'pussies', 'fingerfuckers', 'f4nny', 'n1gga', 'motherfucks', 'ma5terbate', 'hell', 'shagger', 'assfukka', 'masterbat3', 'rimming', 'nigg4h', 'tit', 'fistfucked ', 'shitting', 'god-dam', 'buceta', 'dinks', 'willies', 'tits', 'masterb8', 'bitch', 'blowjobs', 'pawn', 'cipa', 'muff', 'titties', 'm0f0', 'nobjokey', 'masterbation', 'buttmunch', 'prick', 'hotsex', 'scroat', 'motherfuckin', 'cawk', 'cocksucking', 'butthole', 'fuckingshitmotherfucker', 'mothafuckas', 'dink', 'smut', 'titfuck', 'shiting', 'pisser', 'penisfucker', 'ejaculates ', 'shitey', 'l3i+ch', 'shitdick', 'anus', 'kondums', 'kummer', 'felching', 'kawk', 'cumming', 'jizm ', 'twatty', 'orgasms ', 'fcuker', 'poop', 'w00se', 'mothafuckin', 'beastial', 'cok', 'pornography', 'cunts', 'rimjaw', 'fistfuck', 'mofo', 'assfucker', 'niggas', 'c0ck', 'fuckings', 'p0rn', 'fistfuckers ', 'pussy', 'ejaculate', 'tw4t', 'dog-fucker', 'teets', 'gaysex', 'fuck', 'clits', 'duche', 'spunk', 'fux', 'shag', 'mother fucker', 'shitted', 'fucks', 'ass-fucker', 'boiolas', 'jackoff', 'assholes', 'masterbat*', 'schlong', 'cyberfuc', 'boobs', 'fucking', 'bitches', 'cockface', 'testicle', 'shitty ', 'motherfucked', 'motherfuckka', 'shitings', 'fingerfucker ', 'bollock', 'biatch', 'motherfucking', 'fag', 'phuks', 'nobjocky', 'slut', 'fellatio', 'knobjokey', 'nob jokey', 'phuk', 'pusse', 's.o.b.', 'cockmuncher', 'porno', 'whore', 'jizz', 'cocks', 'pron', 'fucker', 'masturbate', 'cumshot', 'nutsack', 'piss', 'God', 'cocksucked ', 'm45terbate', 'b1tch', 'cock-sucker', 'faggot', 'mothafucka', 'wanker', 'ejaculation', 'cunilingus', 'scrotum', 'pissoff ', 'dogging', 'xxx', 'labia', 'c0cksucker', 'cums', 'jism', 'jerk-off ', 'fellate', 'shittings', 'mothafuckings', 'coon', 'pisses ', 'fook', 'fukwit', 'dildos', 'mothafucks', 'cyberfucked ', 'bestial', 'shithead', 'kums', 'motherfuckings', 'cyberfucker', 'fagot', 'bellend', 'numbnuts', '4r5e', 'mothafuckers', 'ejaculating ', 'doggin', 'booobs', 'pissing', 'cuntlicking ', 'muthafecker', 'bugger', 'fcuking', 'cunnilingus', 'jack-off ', 'gangbang', 'fuckwhit', 'cunillingus', 'fistfuckings ', 'knobed', 'knobhead', 'phuq', 'pigfucker', 'scrote', 'nobhead', 'fuk', 'lust', 'l3itch', 'cyalis', 'fuckhead', 'niggers ', '5h1t', 'tittie5', 'sex', 'kondum', 'fanny', 'pecker', 'cyberfuckers', 'b17ch', 'pissin ', 'dyke', 'hoar', 'bitching', 'shaggin', 'clitoris', 'wank', 'fux0r', 'ass', 'bollok', 'cocksukka', 'booooobs', 'orgasim ', 'ar5e', 'cyberfuck ', 'v14gra', 'fcuk', 'titwank', 'a55', 'cl1t', 'booooooobs', 'twunter', 'spac', 'muther', 'porn', 'fukker', 'phonesex', 'kumming', 'nigg3r', 'dildo', 'nigger', 't1tt1e5', 'pricks ', 'retard', 'cuntlick ', 'pube', 'shitfull', 'mothafuckaz', 'fuckers', 'phukking', 'mothafucking ', 'knob', 'cummer', 'hoare', 'fistfucks ', 'cockmunch', 'fucka', 'masterbate', 'shited', 's hit', 'shits', 'fudgepacker', 'bum', 'boner', 'flange', 'm0fo', 'cocksucks ', 'kock', 'arse', 'gangbanged ', 'cunt', 'pissers', 'bunny fucker', 'breasts', 'gaylord', 'niggaz', 'twathead', 'cyberfucking ', 'twunt', 'wanky', 'cuntlicker ', 'asswhole', 'arrse', 'b!tch', 'semen', 'f u c k e r', 'feck', 'teez', 'ejaculated', 'sh1t', 'cnut', 'shi+', 'dick', 'boob', 'b00bs', 'fistfucking ', 'balls', 'boooobs', 'cum', 'fecker', 'motherfuck', 'niggah', 'knobend', 'beastiality', 'cokmuncher', 'pornos', 'fingerfuck ', 'cocksuck ', 'hore', 'fingerfucking ', 'pimpis', 'fuks', 'carpet muncher', 'mothafuck', 'xrated', 'sadist', 'bloody', 'fagging', 'shite', 'horniest', 'tittyfuck', 'dlck', 'nigga', 'f_u_c_k', 'nob', 'titt', 'doosh', 'fagots', 'shitter', 'homo', 'asshole', 'fukwhit', 'lusting', 'ejaculatings', 'smegma', 'masterbations', 'fooker', 'f u c k', 'bastard', 'orgasm', 'pussys ', 'mutherfucker', '5hit', 'fuker', 'jiz ', 'orgasims ', 'bestiality', 'lmfao', 'sh!t', 'dirsa', 't1tties', 'gangbangs '}\n"
     ]
    }
   ],
   "source": [
    "toxic_words_path = \"../data/raw/toxic_words.txt\"\n",
    "\n",
    "toxic_words_set = load_toxic_words(toxic_words_path)\n",
    "print(toxic_words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = RemoverModel(toxic_words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"don ' t say that !\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remover.detoxify(\"Don't fucking say that shit!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
